# coding: utf-8

"""
    FastAPI

    No description provided (generated by Openapi Generator https://github.com/openapitools/openapi-generator)

    The version of the OpenAPI document: 0.1.0
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json


from typing import Any, ClassVar, Dict, List, Optional
from pydantic import BaseModel
from pydantic import Field
from clients.image_gen.models.checkpoint import Checkpoint
from clients.image_gen.models.clip_skip import ClipSkip
from clients.image_gen.models.control_net import ControlNet
from clients.image_gen.models.control_net_early_stop import ControlNetEarlyStop
from clients.image_gen.models.control_net_image import ControlNetImage
from clients.image_gen.models.dictionary_of_lo_ras import DictionaryOfLoRAs
from clients.image_gen.models.dictionary_of_textual_inversions import DictionaryOfTextualInversions
from clients.image_gen.models.fixed_random_seed import FixedRandomSeed
from clients.image_gen.models.image_content_style_transfer_triggers_and_samples import ImageContentStyleTransferTriggersAndSamples
from clients.image_gen.models.image_encoding import ImageEncoding
from clients.image_gen.models.initial_image import InitialImage
from clients.image_gen.models.mask_image import MaskImage
from clients.image_gen.models.negative_prompt import NegativePrompt
from clients.image_gen.models.output_image_height import OutputImageHeight
from clients.image_gen.models.output_image_width import OutputImageWidth
from clients.image_gen.models.pre_defined_styles import PreDefinedStyles
from clients.image_gen.models.scheduler import Scheduler
from clients.image_gen.models.second_input_prompt import SecondInputPrompt
from clients.image_gen.models.second_negative_prompt import SecondNegativePrompt
from clients.image_gen.models.vae import VAE
try:
    from typing import Self
except ImportError:
    from typing_extensions import Self

class ImageGenerationRequest(BaseModel):
    """
    Generate one or more images based on the given parameters.
    """ # noqa: E501
    prompt: Optional[Any] = Field(description="Text describing the image content to generate.")
    prompt_2: Optional[SecondInputPrompt] = None
    negative_prompt: Optional[NegativePrompt] = None
    negative_prompt_2: Optional[SecondNegativePrompt] = None
    checkpoint: Optional[Checkpoint] = None
    controlnet: Optional[ControlNet] = None
    vae: Optional[VAE] = None
    textual_inversions: Optional[DictionaryOfTextualInversions] = None
    loras: Optional[DictionaryOfLoRAs] = None
    sampler: Optional[Scheduler] = None
    height: Optional[OutputImageHeight] = None
    width: Optional[OutputImageWidth] = None
    cfg_scale: Optional[Any] = Field(default=None, description="Floating-point number represeting how closely to adhere to prompt description. Must be a positive number no greater than 50.0.")
    steps: Optional[Any] = Field(default=None, description="Integer repreenting how many steps of diffusion to run. Must be greater than 0 and less than or equal to 200.")
    num_images: Optional[Any] = Field(default=None, description="Integer representing how many output images to generate with a single prompt/configuration.")
    seed: Optional[FixedRandomSeed] = None
    controlnet_image: Optional[ControlNetImage] = None
    init_image: Optional[InitialImage] = None
    mask_image: Optional[MaskImage] = None
    strength: Optional[Any] = Field(default=None, description="Floating-point number indicating how much creative the Image to Image generation mode should be. Must be greater than 0 and less than or equal to 1.0.")
    style_preset: Optional[PreDefinedStyles] = None
    use_refiner: Optional[Any] = Field(default=None, description="Whether to enable and apply the SDXL refiner model to the image generation.")
    high_noise_frac: Optional[Any] = Field(default=None, description="Floating-point number that defines the fraction of steps to perform with the base model. Used only by SD XL. Must be greater than or equal to 0.0 and less than or equal to 1.0.")
    controlnet_conditioning_scale: Optional[Any] = Field(default=None, description="How strong the effect of the controlnet should be.")
    controlnet_early_stop: Optional[ControlNetEarlyStop] = None
    controlnet_preprocess: Optional[Any] = Field(default=None, description="Whether to apply automatic ControlNet preprocessing.")
    clip_skip: Optional[ClipSkip] = None
    outpainting: Optional[Any] = Field(default=None, description="Whether the request requires outpainting or not. If so, special preprocessing is applied for better results.")
    enable_safety: Optional[Any] = Field(default=None, description="Boolean defining whether to use safety checker system on generated outputs or not.")
    image_encoding: Optional[ImageEncoding] = None
    transfer_images: Optional[ImageContentStyleTransferTriggersAndSamples] = None
    force_asset_download: Optional[Any] = Field(default=None, description="[Internal] Boolean defining if assets must be re-downloaded into the cache even if present.")
    force_asset_gpu_copy: Optional[Any] = Field(default=None, description="[Internal] Boolean defining if assets must to be copied into the GPU even if present.")
    additional_properties: Dict[str, Any] = {}
    __properties: ClassVar[List[str]] = ["prompt", "prompt_2", "negative_prompt", "negative_prompt_2", "checkpoint", "controlnet", "vae", "textual_inversions", "loras", "sampler", "height", "width", "cfg_scale", "steps", "num_images", "seed", "controlnet_image", "init_image", "mask_image", "strength", "style_preset", "use_refiner", "high_noise_frac", "controlnet_conditioning_scale", "controlnet_early_stop", "controlnet_preprocess", "clip_skip", "outpainting", "enable_safety", "image_encoding", "transfer_images", "force_asset_download", "force_asset_gpu_copy"]

    model_config = {
        "populate_by_name": True,
        "validate_assignment": True,
        "protected_namespaces": (),
    }


    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Self:
        """Create an instance of ImageGenerationRequest from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        * Fields in `self.additional_properties` are added to the output dict.
        """
        _dict = self.model_dump(
            by_alias=True,
            exclude={
                "additional_properties",
            },
            exclude_none=True,
        )
        # override the default output from pydantic by calling `to_dict()` of prompt_2
        if self.prompt_2:
            _dict['prompt_2'] = self.prompt_2.to_dict()
        # override the default output from pydantic by calling `to_dict()` of negative_prompt
        if self.negative_prompt:
            _dict['negative_prompt'] = self.negative_prompt.to_dict()
        # override the default output from pydantic by calling `to_dict()` of negative_prompt_2
        if self.negative_prompt_2:
            _dict['negative_prompt_2'] = self.negative_prompt_2.to_dict()
        # override the default output from pydantic by calling `to_dict()` of checkpoint
        if self.checkpoint:
            _dict['checkpoint'] = self.checkpoint.to_dict()
        # override the default output from pydantic by calling `to_dict()` of controlnet
        if self.controlnet:
            _dict['controlnet'] = self.controlnet.to_dict()
        # override the default output from pydantic by calling `to_dict()` of vae
        if self.vae:
            _dict['vae'] = self.vae.to_dict()
        # override the default output from pydantic by calling `to_dict()` of textual_inversions
        if self.textual_inversions:
            _dict['textual_inversions'] = self.textual_inversions.to_dict()
        # override the default output from pydantic by calling `to_dict()` of loras
        if self.loras:
            _dict['loras'] = self.loras.to_dict()
        # override the default output from pydantic by calling `to_dict()` of height
        if self.height:
            _dict['height'] = self.height.to_dict()
        # override the default output from pydantic by calling `to_dict()` of width
        if self.width:
            _dict['width'] = self.width.to_dict()
        # override the default output from pydantic by calling `to_dict()` of seed
        if self.seed:
            _dict['seed'] = self.seed.to_dict()
        # override the default output from pydantic by calling `to_dict()` of controlnet_image
        if self.controlnet_image:
            _dict['controlnet_image'] = self.controlnet_image.to_dict()
        # override the default output from pydantic by calling `to_dict()` of init_image
        if self.init_image:
            _dict['init_image'] = self.init_image.to_dict()
        # override the default output from pydantic by calling `to_dict()` of mask_image
        if self.mask_image:
            _dict['mask_image'] = self.mask_image.to_dict()
        # override the default output from pydantic by calling `to_dict()` of style_preset
        if self.style_preset:
            _dict['style_preset'] = self.style_preset.to_dict()
        # override the default output from pydantic by calling `to_dict()` of controlnet_early_stop
        if self.controlnet_early_stop:
            _dict['controlnet_early_stop'] = self.controlnet_early_stop.to_dict()
        # override the default output from pydantic by calling `to_dict()` of clip_skip
        if self.clip_skip:
            _dict['clip_skip'] = self.clip_skip.to_dict()
        # override the default output from pydantic by calling `to_dict()` of transfer_images
        if self.transfer_images:
            _dict['transfer_images'] = self.transfer_images.to_dict()
        # puts key-value pairs in additional_properties in the top level
        if self.additional_properties is not None:
            for _key, _value in self.additional_properties.items():
                _dict[_key] = _value

        # set to None if prompt (nullable) is None
        # and model_fields_set contains the field
        if self.prompt is None and "prompt" in self.model_fields_set:
            _dict['prompt'] = None

        # set to None if cfg_scale (nullable) is None
        # and model_fields_set contains the field
        if self.cfg_scale is None and "cfg_scale" in self.model_fields_set:
            _dict['cfg_scale'] = None

        # set to None if steps (nullable) is None
        # and model_fields_set contains the field
        if self.steps is None and "steps" in self.model_fields_set:
            _dict['steps'] = None

        # set to None if num_images (nullable) is None
        # and model_fields_set contains the field
        if self.num_images is None and "num_images" in self.model_fields_set:
            _dict['num_images'] = None

        # set to None if strength (nullable) is None
        # and model_fields_set contains the field
        if self.strength is None and "strength" in self.model_fields_set:
            _dict['strength'] = None

        # set to None if use_refiner (nullable) is None
        # and model_fields_set contains the field
        if self.use_refiner is None and "use_refiner" in self.model_fields_set:
            _dict['use_refiner'] = None

        # set to None if high_noise_frac (nullable) is None
        # and model_fields_set contains the field
        if self.high_noise_frac is None and "high_noise_frac" in self.model_fields_set:
            _dict['high_noise_frac'] = None

        # set to None if controlnet_conditioning_scale (nullable) is None
        # and model_fields_set contains the field
        if self.controlnet_conditioning_scale is None and "controlnet_conditioning_scale" in self.model_fields_set:
            _dict['controlnet_conditioning_scale'] = None

        # set to None if controlnet_preprocess (nullable) is None
        # and model_fields_set contains the field
        if self.controlnet_preprocess is None and "controlnet_preprocess" in self.model_fields_set:
            _dict['controlnet_preprocess'] = None

        # set to None if outpainting (nullable) is None
        # and model_fields_set contains the field
        if self.outpainting is None and "outpainting" in self.model_fields_set:
            _dict['outpainting'] = None

        # set to None if enable_safety (nullable) is None
        # and model_fields_set contains the field
        if self.enable_safety is None and "enable_safety" in self.model_fields_set:
            _dict['enable_safety'] = None

        # set to None if force_asset_download (nullable) is None
        # and model_fields_set contains the field
        if self.force_asset_download is None and "force_asset_download" in self.model_fields_set:
            _dict['force_asset_download'] = None

        # set to None if force_asset_gpu_copy (nullable) is None
        # and model_fields_set contains the field
        if self.force_asset_gpu_copy is None and "force_asset_gpu_copy" in self.model_fields_set:
            _dict['force_asset_gpu_copy'] = None

        return _dict

    @classmethod
    def from_dict(cls, obj: Dict) -> Self:
        """Create an instance of ImageGenerationRequest from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate({
            "prompt": obj.get("prompt"),
            "prompt_2": SecondInputPrompt.from_dict(obj.get("prompt_2")) if obj.get("prompt_2") is not None else None,
            "negative_prompt": NegativePrompt.from_dict(obj.get("negative_prompt")) if obj.get("negative_prompt") is not None else None,
            "negative_prompt_2": SecondNegativePrompt.from_dict(obj.get("negative_prompt_2")) if obj.get("negative_prompt_2") is not None else None,
            "checkpoint": Checkpoint.from_dict(obj.get("checkpoint")) if obj.get("checkpoint") is not None else None,
            "controlnet": ControlNet.from_dict(obj.get("controlnet")) if obj.get("controlnet") is not None else None,
            "vae": VAE.from_dict(obj.get("vae")) if obj.get("vae") is not None else None,
            "textual_inversions": DictionaryOfTextualInversions.from_dict(obj.get("textual_inversions")) if obj.get("textual_inversions") is not None else None,
            "loras": DictionaryOfLoRAs.from_dict(obj.get("loras")) if obj.get("loras") is not None else None,
            "sampler": obj.get("sampler"),
            "height": OutputImageHeight.from_dict(obj.get("height")) if obj.get("height") is not None else None,
            "width": OutputImageWidth.from_dict(obj.get("width")) if obj.get("width") is not None else None,
            "cfg_scale": obj.get("cfg_scale"),
            "steps": obj.get("steps"),
            "num_images": obj.get("num_images"),
            "seed": FixedRandomSeed.from_dict(obj.get("seed")) if obj.get("seed") is not None else None,
            "controlnet_image": ControlNetImage.from_dict(obj.get("controlnet_image")) if obj.get("controlnet_image") is not None else None,
            "init_image": InitialImage.from_dict(obj.get("init_image")) if obj.get("init_image") is not None else None,
            "mask_image": MaskImage.from_dict(obj.get("mask_image")) if obj.get("mask_image") is not None else None,
            "strength": obj.get("strength"),
            "style_preset": PreDefinedStyles.from_dict(obj.get("style_preset")) if obj.get("style_preset") is not None else None,
            "use_refiner": obj.get("use_refiner"),
            "high_noise_frac": obj.get("high_noise_frac"),
            "controlnet_conditioning_scale": obj.get("controlnet_conditioning_scale"),
            "controlnet_early_stop": ControlNetEarlyStop.from_dict(obj.get("controlnet_early_stop")) if obj.get("controlnet_early_stop") is not None else None,
            "controlnet_preprocess": obj.get("controlnet_preprocess"),
            "clip_skip": ClipSkip.from_dict(obj.get("clip_skip")) if obj.get("clip_skip") is not None else None,
            "outpainting": obj.get("outpainting"),
            "enable_safety": obj.get("enable_safety"),
            "image_encoding": obj.get("image_encoding"),
            "transfer_images": ImageContentStyleTransferTriggersAndSamples.from_dict(obj.get("transfer_images")) if obj.get("transfer_images") is not None else None,
            "force_asset_download": obj.get("force_asset_download"),
            "force_asset_gpu_copy": obj.get("force_asset_gpu_copy")
        })
        # store additional fields in additional_properties
        for _key in obj.keys():
            if _key not in cls.__properties:
                _obj.additional_properties[_key] = obj.get(_key)

        return _obj


